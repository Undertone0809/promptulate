{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Math Application with promptulate Agents\n",
    "This demo is how to use promptulates agents to create a custom Math application utilising OpenAI's GPT3.5 Model.\n",
    "For the application frontend, there will be using streamlit, an easy-to-use open-source Python framework. \n",
    "This generative math application, letâ€™s call it â€œMath Wizâ€, is designed to help users with their math or reasoning/logic questions.\n",
    "\n",
    "## Reference reading\n",
    "[Building a Math Application with LangChain Agents](https://towardsdatascience.com/building-a-math-application-with-langchain-agents-23919d09a4d3)\n",
    "\n",
    "the app schema for â€œMath Wizâ€ looks like the following:\n",
    "![App-Schema-for-Math-Wiz diagram](./img/App-Schema-for-Math-Wiz.png)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7207979682ff90d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "We can start off by creating a new conda environment with python=3.11:`conda create -n math_assistant python=3.11`\n",
    "\n",
    "Activate the environment:`conda activate math_assistant`\n",
    "\n",
    "Next, letâ€™s install all necessary libraries:\n",
    "`pip install -U promptulate` \n",
    "`pip install wikipedia`\n",
    "`pip install numexpr`\n",
    "\n",
    "Sign up at OpenAI and obtain your own key to start making calls to the gpt model. Once you have the key, create a .env file in your repository and store the OpenAI key:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c14bd58db4084624"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"your_openai_api_key\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:31.638818200Z",
     "start_time": "2024-04-25T12:50:31.622348700Z"
    }
   },
   "id": "bdba0ee6cdddfda1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Application Flow\n",
    "The application flow for Math Wiz is outlined in the flowchart below. The agent in our pipeline will have a set of tools at its disposal that it can use to answer a user query. The Large Language Model (LLM) serves as the â€œbrainâ€ of the agent, guiding its decisions. When a user submits a question, the agent uses the LLM to select the most appropriate tool or a combination of tools to provide an answer. If the agent determines it needs multiple tools, it will also specify the order in which the tools are used.\n",
    "![Promptulate-Agents-Deconstructed](./img/Promptulate-Agents-Deconstructed.png)\n",
    "\n",
    "**The application flow for Math Wiz is outlined below:**\n",
    "\n",
    "The agent in our pipeline will have a set of tools at its disposal that it can use to answer a user query. The Large Language Model (LLM) serves as the â€œbrainâ€ of the agent, guiding its decisions. When a user submits a question, the agent uses the LLM to select the most appropriate tool or a combination of tools to provide an answer. If the agent determines it needs multiple tools, it will also specify the order in which the tools are used.\n",
    "\n",
    "The agent for our Math Wiz app will be using the following tools:\n",
    "\n",
    "1. **Wikipedia Tool:** this tool will be responsible for fetching the latest information from Wikipedia using the Wikipedia API. While there are paid tools and APIs available that can be integrated inside LangChain, I would be using Wikipedia as the appâ€™s online source of information.\n",
    "\n",
    "2. **Calculator Tool:** this tool would be responsible for solving a userâ€™s math queries. This includes anything involving numerical calculations. For example, if a user asks what the square root of 4 is, this tool would be appropriate.\n",
    "\n",
    "3. **Reasoning Tool:** the final tool in our application setup would be a reasoning tool, responsible for tackling logical/reasoning-based user queries. Any mathematical word problems should also be handled with this tool.\n",
    "\n",
    "Now that we have a rough application design, we can begin thinking about building this application."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57d30c50ed555e46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding promptulate Agents\n",
    "\n",
    "Promptulate agents are designed to enhance interaction with language models by providing an interface for more complex and interactive tasks. We can think of an agent as an intermediary between users and a large language model. Agents seek to break down a seemingly complex user query, that our LLM might not be able to tackle on its own, into easier, actionable steps.\n",
    "\n",
    "In our application flow, we defined a few different tools that we would like to use for our math application. Based on the user input, the agent should decide which of these tools to use. If a tool is not required, it should not be used. Promptulate agents can simplify this for us. These agents use a language model to choose a sequence of actions to take. Essentially, the LLM acts as the â€œbrainâ€ of the agent, guiding it on which tool to use for a particular query, and in which order. This is different from Proptulate chains where the sequence of actions are hardcoded in code. Promptulate offers a wide set of tools that can be integrated with an agent. These tools include, and are not limited to, online search tools, API-based tools, chain-based tools etc. For more information on Promptulate agents and their types, see [this](https://undertone0809.github.io/promptulate/#/modules/agent?id=agent)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eac444b133599049"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step-by-Step Implementation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "580a0bd570fd6545"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1\n",
    "\n",
    "Create a `chatbot.py` script and import the necessary dependencies:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22e6af33468bbed4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from promptulate.llms import ChatOpenAI\n",
    "from promptulate.tools.wikipedia.tools import wikipedia_search\n",
    "from promptulate.tools.math.tools import calculator\n",
    "import promptulate as pne"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:33.882702800Z",
     "start_time": "2024-04-25T12:50:31.643335600Z"
    }
   },
   "id": "bf24915502504abb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2\n",
    "Next, we will define our OpenAI-based Language Model.The architectural design of `promptulate` is easily compatible with different large language model extensions. In `promptulate`, llm is responsible for the most basic part of content generation, so it is the most basic component.By default, `ChatOpenAI` in `promptulate` uses the `gpt-3.5-turbo` model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24cf6e82bd6c908e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:33.898006100Z",
     "start_time": "2024-04-25T12:50:33.885707Z"
    }
   },
   "id": "ca8d4ef8b9b9bcc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We would be using this LLM both within our math and reasoning process and as the decision maker for our agent."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "479c360af07d9a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3\n",
    "When constructing your own agent, you will need to provide it with a list of tools that it can use. Difine a toolï¼Œ the only you need to do is to provide a function to Promptulate. Promptulate will automatically convert it to a tool that can be used by the language learning model (LLM). The final presentation result it presents to LLM is an OpenAI type JSON schema declaration.\n",
    "\n",
    "Actually, Promptulate will analysis function name, parameters type, parameters attribution, annotations and docs when you provide the function. We strongly recommend that you use the official best practices of Template for function writing. The best implementation of a function requires adding type declarations to its parameters and providing function level annotations. Ideally, declare the meaning of each parameter within the annotations.\n",
    "\n",
    "We will now create our three tools. The first one will be the online tool using the Wikipedia API wrapper:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b9b2c90ec135c6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Wikipedia Tool\n",
    "def wikipedia_tool(keyword: str) -> str:\n",
    "    \"\"\"search by keyword in web.\n",
    "\n",
    "    A useful tool for searching the Internet to find information on world events,\n",
    "    issues, dates,years, etc. Worth using for general topics. Use precise questions.\n",
    "\n",
    "    Args:\n",
    "        keyword: keyword to search\n",
    "\n",
    "    Returns:\n",
    "        str: search result\n",
    "    \"\"\"\n",
    "    return wikipedia_search(keyword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:33.922888100Z",
     "start_time": "2024-04-25T12:50:33.901242300Z"
    }
   },
   "id": "2432245bfeb3ec83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, letâ€™s define the tool that we will be using for calculating any numerical expressions. `Promptulate` offers the `calculator` which uses the `numexpr` Python library to calculate mathematical expressions. It is also important that we clearly define what this tool would be used for. The description can be helpful for the agent in deciding which tool to use from a set of tools for a particular user query. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd71e0b1f2e2b3ba"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# calculator tool for arithmetics\n",
    "def math_tool(expression: str):\n",
    "    \"\"\"Useful for when you need to answer questions about math. This tool is only\n",
    "    for math questions and nothing else. Only input math expressions.\n",
    "\n",
    "    Args:\n",
    "        expression: A mathematical expression, eg: 18^0.43\n",
    "\n",
    "    Attention:\n",
    "        Expressions can not exist variables!\n",
    "        eg: (current age)^0.43 is wrong, you should use 18^0.43 instead.\n",
    "\n",
    "    Returns:\n",
    "        The result of the evaluation.\n",
    "    \"\"\"\n",
    "    return calculator(expression)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:33.934913700Z",
     "start_time": "2024-04-25T12:50:33.915470300Z"
    }
   },
   "id": "f34cd4480745694b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we will be defining the tool for logic/reasoning-based queries. We will first create a prompt to instruct the model with executing the specific task. Then we will create a simple `AssistantMessage` for this tool, passing it the LLM and the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ffdb61331ee9735"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# reasoning based tool\n",
    "def word_problem_tool(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Useful for when you need to answer logic-based/reasoning questions.\n",
    "\n",
    "    Args:\n",
    "        question(str): Detail question, the description of the problem requires a\n",
    "        detailed question context. Include a description of the problem\n",
    "\n",
    "    Returns:\n",
    "        question answer\n",
    "    \"\"\"\n",
    "    system_prompt: str = \"\"\"You are a reasoning agent tasked with solving t he user's logic-based questions.\n",
    "    Logically arrive at the solution, and be factual.\n",
    "    In your answers, clearly detail the steps involved and give the final answer.\n",
    "    Provide the response in bullet points.\"\"\"  # noqa\n",
    "    llm = ChatOpenAI()\n",
    "    return llm(f\"{system_prompt}\\n\\nQuestion:{question}Answer:\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:33.943505500Z",
     "start_time": "2024-04-25T12:50:33.931406600Z"
    }
   },
   "id": "9e135028cb2f3b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4\n",
    "We will now initialize our agent with the tools we have created above. We will also specify the LLM to help it choose which tools to use and in what order:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0dec33956572b1a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31;1m\u001B[1;3m[Agent] Tool Agent start...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m[User instruction] I have 3 apples and 4 oranges.I give half of my oranges away and buy two dozen new ones,along with three packs of strawberries.Each pack of strawberry has 30 strawberries.How many total pieces of fruit do I have at the end?\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Thought] I should break down the problem step by step and calculate the total number of fruits at the end.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Action] word_problem_tool args: {'question': 'I have 3 apples and 4 oranges. I give half of my oranges away and buy two dozen new ones, along with three packs of strawberries. Each pack of strawberry has 30 strawberries. How many total pieces of fruit do I have at the end?'}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m[Observation] To solve this problem, we can break it down into steps and calculate the total number of fruit pieces you have at the end:\n",
      "\n",
      "Initial fruits:\n",
      "- 3 apples\n",
      "- 4 oranges\n",
      "\n",
      "Giving away half of the oranges:\n",
      "- You have 4 oranges, so you give away 4/2 = 2 oranges.\n",
      "- After giving away 2 oranges, you have 4 - 2 = 2 oranges remaining.\n",
      "\n",
      "Buying new fruits:\n",
      "- You buy 2 dozen new oranges, where 1 dozen is equal to 12.\n",
      "- 2 dozen oranges is 2 * 12 = 24 oranges.\n",
      "- You also buy 3 packs of strawberries, with each pack having 30 strawberries.\n",
      "- Total strawberries bought = 3 * 30 = 90 strawberries.\n",
      "\n",
      "Calculating total fruit pieces at the end:\n",
      "- After giving away half of your oranges, you have 2 oranges left.\n",
      "- Adding the new oranges bought, you have a total of 2 + 24 = 26 oranges.\n",
      "- You initially had 3 apples, so the total apples remain 3.\n",
      "- You bought 90 strawberries.\n",
      "- Total fruits at the end = Total oranges + Total apples + Total strawberries\n",
      "- Total fruits = 26 oranges + 3 apples + 90 strawberries = 26 + 3 + 90 = 119 pieces of fruit\n",
      "\n",
      "Therefore, at the end of the scenario, you have a total of 119 pieces of fruit.\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m[Agent Result] You have a total of 119 pieces of fruit at the end of the scenario.\u001B[0m\n",
      "\u001B[38;5;200m\u001B[1;3m[Agent] Agent End.\u001B[0m\n",
      "You have a total of 119 pieces of fruit at the end of the scenario.\n"
     ]
    }
   ],
   "source": [
    "# agent\n",
    "agent = pne.ToolAgent(tools=[wikipedia_tool, math_tool, word_problem_tool],\n",
    "                      llm=llm)\n",
    "\n",
    "resp: str = agent.run(\"I have 3 apples and 4 oranges.I give half of my oranges away and buy two dozen new ones,along with three packs of strawberries.Each pack of strawberry has 30 strawberries.How many total pieces of fruit do I have at the end?\")\n",
    "print(resp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T12:50:49.577054200Z",
     "start_time": "2024-04-25T12:50:33.946018700Z"
    }
   },
   "id": "5b03977f863172b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The appâ€™s response to a logic question is following:**\n",
    "![test-question-answer](./img/test-question-answer.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f03211a6b5fdb861"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating streamlit application\n",
    "We will be using Streamlit, an open-source Python framework, to build our application. With Streamlit, you can build conversational AI applications with a few simple lines of code. Using streamlit to build the demo of application is demonstrated in the peer child file `chabot.py` of the notebook file. You can run the file directly with the command `streamlit run chatbot.py` to view the effect and debug the web page.\n",
    "\n",
    "Letâ€™s begin by importing the Streamlit package to our `chatbot.py` script: `pip install Streamlit == 1.28`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39bc55b81b5726e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import streamlit as st"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ecaa3b83376028"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then,let's build a lifecycle class to display the intermediate state of the agent response on the chat page.If you want to learn more about the life cycle, please click [here](https://undertone0809.github.io/promptulate/#/modules/hook?id=what-is-hook)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b4527400237d55a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from promptulate.hook import Hook, HookTable\n",
    "\n",
    "class MidStepOutHook:\n",
    "    @staticmethod\n",
    "    def handle_agent_revise_plan(*args, **kwargs):\n",
    "        messages = f\"[Revised Plan] {kwargs['revised_plan']}\"\n",
    "        st.chat_message(\"assistant\").write(messages)\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_agent_action(*args, **kwargs):\n",
    "        messages = f\"[Thought] {kwargs['thought']}\\n\"\n",
    "        messages += f\"[Action] {kwargs['action']} args: {kwargs['action_input']}\"\n",
    "        st.chat_message(\"assistant\").write(messages)\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_agent_observation(*args, **kwargs):\n",
    "        messages = f\"[Observation] {kwargs['observation']}\"\n",
    "        st.chat_message(\"assistant\").write(messages)\n",
    "\n",
    "    @staticmethod\n",
    "    def registry_hooks():\n",
    "        \"\"\"Registry and enable stdout hooks. StdoutHook can print colorful\n",
    "        information.\"\"\"\n",
    "        Hook.registry_hook(\n",
    "            HookTable.ON_AGENT_REVISE_PLAN,\n",
    "            MidStepOutHook.handle_agent_revise_plan,\n",
    "            \"component\",\n",
    "        )\n",
    "        Hook.registry_hook(\n",
    "            HookTable.ON_AGENT_ACTION, MidStepOutHook.handle_agent_action, \"component\"\n",
    "        )\n",
    "        Hook.registry_hook(\n",
    "            HookTable.ON_AGENT_OBSERVATION,\n",
    "            MidStepOutHook.handle_agent_observation,\n",
    "            \"component\",\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e517dd3917eac23d"
  },
  {
   "cell_type": "markdown",
   "source": [
    " Next,Let's build a function,and We will be adding our LLM, tools and agent initialization code to this function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f7070149d83cc52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_agent(api_key: str) -> pne.ToolAgent:\n",
    "    MidStepOutHook.registry_hooks()\n",
    "\n",
    "    # calculator tool for arithmetics\n",
    "    def math_tool(expression: str):\n",
    "        \"\"\"Useful for when you need to answer questions about math. This tool is only\n",
    "        for math questions and nothing else. Only input math expressions.\n",
    "\n",
    "        Args:\n",
    "            expression: A mathematical expression, eg: 18^0.43\n",
    "\n",
    "        Attention:\n",
    "            Expressions can not exist variables!\n",
    "            eg: (current age)^0.43 is wrong, you should use 18^0.43 instead.\n",
    "\n",
    "        Returns:\n",
    "            The result of the evaluation.\n",
    "        \"\"\"\n",
    "        return calculator(expression)\n",
    "\n",
    "    # reasoning based tool\n",
    "    def word_problem_tool(question: str) -> str:\n",
    "        \"\"\"\n",
    "        Useful for when you need to answer logic-based/reasoning questions.\n",
    "\n",
    "        Args:\n",
    "            question(str): Detail question, the description of the problem requires a\n",
    "            detailed question context. Include a description of the problem\n",
    "\n",
    "        Returns:\n",
    "            question answer\n",
    "        \"\"\"\n",
    "        system_prompt: str = \"\"\"You are a reasoning agent tasked with solving t he user's logic-based questions.\n",
    "        Logically arrive at the solution, and be factual.\n",
    "        In your answers, clearly detail the steps involved and give the final answer.\n",
    "        Provide the response in bullet points.\"\"\"  # noqa\n",
    "        llm = ChatOpenAI(private_api_key=api_key)\n",
    "        return llm(f\"{system_prompt}\\n\\nQuestion:{question}Answer:\")\n",
    "\n",
    "    # Wikipedia Tool\n",
    "    def wikipedia_tool(keyword: str) -> str:\n",
    "        \"\"\"search by keyword in web.\n",
    "\n",
    "        A useful tool for searching the Internet to find information on world events,\n",
    "        issues, dates,years, etc. Worth using for general topics. Use precise questions.\n",
    "\n",
    "        Args:\n",
    "            keyword: keyword to search\n",
    "\n",
    "        Returns:\n",
    "            str: search result\n",
    "        \"\"\"\n",
    "        return wikipedia_search(keyword)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4-1106-preview\", private_api_key=api_key)\n",
    "    return pne.ToolAgent(tools=[wikipedia_tool, math_tool, word_problem_tool], llm=llm)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "501a05d4f38f2569"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the style of our application"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7e22b43ffb8cfd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a sidebar to place the user parameter configuration\n",
    "with st.sidebar:\n",
    "    openai_api_key = st.text_input(\n",
    "        \"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\"\n",
    "    )\n",
    "    \"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)\"\n",
    "    \"[View the source code](https://github.com/hizeros/llm-streamlit/blob/master/Chatbot.py)\"  # noqa\n",
    "    \n",
    "# Set title\n",
    "st.title(\"ðŸ’¬ Math Wiz\")\n",
    "st.caption(\"ðŸš€ Hi there! ðŸ‘‹ I am a reasoning tool by Promptulate to help you \"\n",
    "           \"with your math or logic-based reasoning questions.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96eaa93e6ee98926"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, check our session state and render the user input and agent response to the chat page, so that we successfully build a simple math application using streamlit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67f50ffe7e9438b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Determine whether to initialize the message variable\n",
    "# otherwise initialize a message dictionary\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = [\n",
    "        {\"role\": \"assistant\", \"content\": \"How can I help you?\"}\n",
    "    ]\n",
    "\n",
    "# Traverse messages in session state\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "# User input\n",
    "if prompt := st.chat_input():\n",
    "    if not openai_api_key:\n",
    "        st.info(\"Please add your OpenAI API key to continue.\")\n",
    "        st.stop()\n",
    "\n",
    "    agent: pne.ToolAgent = build_agent(api_key=openai_api_key)\n",
    "\n",
    "    # Add the message entered by the user to the list of messages in the session state\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    # Display in the chat interface\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "\n",
    "    response: str = agent.run(prompt)\n",
    "\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    st.chat_message(\"assistant\").write(response)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ce1ad0ef01b4f8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try to run it: `streamlit run chatbot.py` in current directory.\n",
    "The running result is as follows:\n",
    "![streamlit-application-run](./img/streamlit-application-run.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee23a017637f8a4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also run it in your local environment. Try to run the following command:\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/Undertone0809/promptulate.git\n",
    "cd promptulate/example/build-math-application-with-agent\n",
    "pip install -r ./requirements.txt\n",
    "streamlit run chatbot.py\n",
    "```\n",
    "\n",
    "\n",
    "Examples of other questions are given below for testing reference:\n",
    "1. Question 1\n",
    "    - I have 3 apples and 4 oranges.I give half of my oranges away and buy two dozen new ones,along with three packs of strawberries.Each pack of strawberry has 30 strawberries.How many total pieces of fruit do I have at the end?\n",
    "    - correct answer = 119\n",
    "2. Question 2\n",
    "    - What is the cube root of 625?\n",
    "    - correct answer = 8.5498\n",
    "3. Question 3\n",
    "    - what is cube root of 81? Multiply with 13.27, and subtract 5.\n",
    "    - correct answer = 52.4195\n",
    "4. Question 4\n",
    "    - Steve's sister is 10 years older than him. Steve was born when the cold war \n",
    "ended. When was Steve's sister born?\n",
    "    - correct answer = 1991 - 10 = 1981\n",
    "5. Question 5\n",
    "    - give me the year when Tom Cruise's Top Gun released raised to the power 2\n",
    "    - correct answer = 1987**2 = 3944196"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71856097c6236dd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8068dc457fb51151"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
